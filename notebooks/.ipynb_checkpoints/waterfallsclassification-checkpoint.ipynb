{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 02:14:30.372441: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-06-06 02:14:30.424131: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "from keras import layers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.models import Model, load_model\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.layers import Input, Dropout, Add, Dense, Reshape, Activation\n",
    "from keras.layers import BatchNormalization, Flatten, Conv2D, MaxPooling1D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## ML Flow Tracking Server\n",
    "\n",
    "I have ML Flow running locally.  When I start it it exports the IP and port it will use.  Here, we try to read those in and track experiments if the ML Flow server is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLFLOW_IP = os.getenv('MLFLOW_IP')\n",
    "MLFLOW_PORT = os.getenv('MLFLOW_PORT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "mlflow.set_tracking_uri(\"http://localhost:7780\")\n",
    "mlflow.set_experiment(\"ResNet for Waterfall Plots\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/06/06 02:14:32 INFO mlflow.tracking.fluent: Autologging successfully enabled for keras.\n",
      "2025/06/06 02:14:32 INFO mlflow.tracking.fluent: Autologging successfully enabled for tensorflow.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup ML Flow\n"
     ]
    }
   ],
   "source": [
    "mlflow.autolog()\n",
    "print(\"Setup ML Flow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Config\n",
    "\n",
    "Check that it's available, and configure it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs detected: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-06 02:14:32.256758: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-06 02:14:32.278428: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-06-06 02:14:32.282434: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(\"GPUs detected:\", gpus)\n",
    "for gpu in tf.config.list_physical_devices('GPU'):\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/remote-keyless-entry/d2d40fcad82f4b48808ca0003035f9bf.png (302, 302, 3)\n",
      "./datasets/remote-keyless-entry/055c6c36bf883f7c5c859f3d5a5e3728.png (480, 573, 4)\n",
      "./datasets/remote-keyless-entry/920e00156b7ad9dfb493a45f419d637a.png (473, 743, 4)\n",
      "./datasets/remote-keyless-entry/4bdb9f096b373092d2681b2b3ae0ad64.png (490, 619, 4)\n",
      "./datasets/pocsag/c946a9e946188e5f4ddfbe6a6f5fef83.jpg (427, 1459, 3)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m counter \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m30\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      9\u001b[0m     counter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 10\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(dirname \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m filename, img\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/pyplot.py:2615\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   2611\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(matplotlib\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimread)\n\u001b[1;32m   2612\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimread\u001b[39m(\n\u001b[1;32m   2613\u001b[0m         fname: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath \u001b[38;5;241m|\u001b[39m BinaryIO, \u001b[38;5;28mformat\u001b[39m: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2614\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray:\n\u001b[0;32m-> 2615\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmatplotlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/image.py:1521\u001b[0m, in \u001b[0;36mimread\u001b[0;34m(fname, format)\u001b[0m\n\u001b[1;32m   1515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1516\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease open the URL for reading and pass the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1517\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresult to Pillow, e.g. with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m``np.array(PIL.Image.open(urllib.request.urlopen(url)))``.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1519\u001b[0m         )\n\u001b[1;32m   1520\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m img_open(fname) \u001b[38;5;28;01mas\u001b[39;00m image:\n\u001b[0;32m-> 1521\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43m_pil_png_to_float_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(image, PIL\u001b[38;5;241m.\u001b[39mPngImagePlugin\u001b[38;5;241m.\u001b[39mPngImageFile) \u001b[38;5;28;01melse\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m             pil_to_array(image))\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/image.py:1721\u001b[0m, in \u001b[0;36m_pil_png_to_float_array\u001b[0;34m(pil_png)\u001b[0m\n\u001b[1;32m   1719\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mdivide(pil_png\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGBA\u001b[39m\u001b[38;5;124m\"\u001b[39m), \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m8\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m   1720\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGBA\u001b[39m\u001b[38;5;124m\"\u001b[39m:  \u001b[38;5;66;03m# RGBA.\u001b[39;00m\n\u001b[0;32m-> 1721\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdivide\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpil_png\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1722\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown PIL rawmode: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrawmode\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py:673\u001b[0m, in \u001b[0;36mImage.__array_interface__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    671\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtobytes(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mL\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 673\u001b[0m         new[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtobytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, (\u001b[38;5;167;01mMemoryError\u001b[39;00m, \u001b[38;5;167;01mRecursionError\u001b[39;00m)):\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/Image.py:732\u001b[0m, in \u001b[0;36mImage.tobytes\u001b[0;34m(self, encoder_name, *args)\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m args \u001b[38;5;241m==\u001b[39m ():\n\u001b[1;32m    730\u001b[0m     args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[0;32m--> 732\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    735\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/PIL/ImageFile.py:269\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    268\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 269\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "count = 50\n",
    "counter = 0\n",
    "DATASET_ROOT_DIR = './datasets'\n",
    "for dirname, _, filenames in os.walk(DATASET_ROOT_DIR):\n",
    "    for filename in filenames:        \n",
    "        counter += 1\n",
    "        if counter % 30 == 0:\n",
    "            counter = 0\n",
    "            img = plt.imread(dirname + '/' + filename)\n",
    "            print(dirname + '/' + filename, img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './datasets/automatic-picture-transmission/f7a3be24e8b2f2755e07bd98b474f09e.png'\n",
    "IMGSIZE=(128,128)\n",
    "img = cv2.resize(cv2.imread(file), IMGSIZE)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './datasets/lora/40fd4bd65f1e7dc0a7240387ca96cefb.png'\n",
    "IMGSIZE=(128,128)\n",
    "img = cv2.resize(cv2.imread(file), IMGSIZE)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = './datasets/vor/fd6e4c3603fccd0ae9e611350e7e284a.png'\n",
    "IMGSIZE=(128,128)\n",
    "img = cv2.resize(cv2.imread(file), IMGSIZE)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, val_ds = keras.utils.image_dataset_from_directory(\n",
    "    DATASET_ROOT_DIR,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    class_names=None,\n",
    "    color_mode=\"rgb\",\n",
    "    batch_size=32,\n",
    "    image_size=(256, 256),\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    validation_split=.2,\n",
    "    subset=\"both\",\n",
    "    interpolation=\"bilinear\",\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionBlock(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, strides=1, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "\n",
    "        # First convolution\n",
    "        self.conv1 = layers.Conv2D(\n",
    "            filters,\n",
    "            kernel_size,\n",
    "            strides=strides,\n",
    "            padding='same', # Use 'same' padding to maintain spatial dimensions\n",
    "            use_bias=False \n",
    "        )\n",
    "        # Batch Normalization after convolution\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        # Activation (usually ReLU)\n",
    "        self.relu = layers.Activation('relu')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Apply the layers sequentially\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "# Define the Identity Block (Residual Block)\n",
    "# This block is used when the input and output shapes of the block\n",
    "# are the same, allowing the shortcut connection to be a simple identity mapping.\n",
    "class IdentityBlock(layers.Layer):\n",
    "    def __init__(self, filters, kernel_size, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        self.conv1 = layers.Conv2D(filters, kernel_size, padding='same', use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu1 = layers.Activation('relu')\n",
    "\n",
    "        self.conv2 = layers.Conv2D(filters, kernel_size, padding='same', use_bias=False)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Store the input for the shortcut connection\n",
    "        shortcut = inputs\n",
    "\n",
    "        # Main Path\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        x = layers.Add()([x, shortcut])\n",
    "\n",
    "        # Apply final activation after the addition\n",
    "        x = layers.Activation('relu')(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " class SimpleResNet(keras.Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Initial Convolution and Pooling\n",
    "        self.conv1 = layers.Conv2D(64, 7, strides=2, padding='same', use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu1 = layers.Activation('relu')\n",
    "        self.max_pool = layers.MaxPooling2D(3, strides=2, padding='same')\n",
    "\n",
    "        self.id_block1 = IdentityBlock(filters=64, kernel_size=3)\n",
    "        self.id_block2 = IdentityBlock(filters=64, kernel_size=3)\n",
    "\n",
    "        # A convolution block to change dimensions, followed by identity blocks\n",
    "        # self.conv_block1 = ConvolutionBlock(filters=128, kernel_size=3, strides=2) # Stride 2 reduces spatial size\n",
    "        # self.id_block3 = IdentityBlock(filters=128, kernel_size=3)\n",
    "\n",
    "        # Global Average Pooling\n",
    "        self.global_avg_pool = layers.GlobalAveragePooling2D()\n",
    "\n",
    "        # Dense layer for classification\n",
    "        self.classifier = layers.Dense(num_classes, activation='softmax') # Use softmax for multi-class output\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs should be (batch_size, 256, 256, 3)\n",
    "\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        # Apply residual blocks\n",
    "        x = self.id_block1(x)\n",
    "        x = self.id_block2(x)\n",
    "\n",
    "        # If using convolution block:\n",
    "        # x = self.conv_block1(x)\n",
    "        # x = self.id_block3(x)\n",
    "\n",
    "        # Final layers\n",
    "        x = self.global_avg_pool(x)\n",
    "        outputs = self.classifier(x)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionBlock(layers.Layer):\n",
    "    # Keep ConvolutionBlock as is, its layers are simple and built on first call\n",
    "    def __init__(self, filters, kernel_size, strides=1, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "        self.strides = strides\n",
    "\n",
    "        # First convolution\n",
    "        self.conv1 = layers.Conv2D(\n",
    "            filters,\n",
    "            kernel_size,\n",
    "            strides=strides,\n",
    "            padding='same',\n",
    "            use_bias=False\n",
    "        )\n",
    "        # Batch Normalization after convolution\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        # Activation (usually ReLU)\n",
    "        self.relu = layers.Activation('relu')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class IdentityBlock(layers.Layer):\n",
    "    # Keep IdentityBlock as is, its layers are simple and built on first call\n",
    "    def __init__(self, filters, kernel_size, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.filters = filters\n",
    "        self.kernel_size = kernel_size\n",
    "\n",
    "        self.conv1 = layers.Conv2D(filters, kernel_size, padding='same', use_bias=False)\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.relu1 = layers.Activation('relu')\n",
    "\n",
    "        self.conv2 = layers.Conv2D(filters, kernel_size, padding='same', use_bias=False)\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "\n",
    "    def call(self, inputs):\n",
    "        shortcut = inputs\n",
    "\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "\n",
    "        x = layers.Add()([x, shortcut])\n",
    "\n",
    "        x = layers.Activation('relu')(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class SimpleResNet(keras.Model):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        # Layers are now created in the build method\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # input_shape will be something like (None, 256, 256, 3)\n",
    "\n",
    "        # Initial Convolution and Pooling\n",
    "        self.conv1 = layers.Conv2D(64, 7, strides=2, padding='same', use_bias=False, name='conv1')\n",
    "        self.bn1 = layers.BatchNormalization(name='bn1')\n",
    "        self.relu1 = layers.Activation('relu', name='relu1')\n",
    "        self.max_pool = layers.MaxPooling2D(3, strides=2, padding='same', name='max_pool')\n",
    "\n",
    "        # Residual Blocks\n",
    "        # Pass the filters explicitly here\n",
    "        self.id_block1 = IdentityBlock(filters=64, kernel_size=3, name='id_block1')\n",
    "        self.id_block2 = IdentityBlock(filters=64, kernel_size=3, name='id_block2')\n",
    "\n",
    "        self.conv_block1 = ConvolutionBlock(filters=128, kernel_size=3, strides=2, name='conv_block1')\n",
    "        self.id_block3 = IdentityBlock(filters=128, kernel_size=3, name='id_block3')\n",
    "\n",
    "\n",
    "        # Global Average Pooling\n",
    "        self.global_avg_pool = layers.GlobalAveragePooling2D(name='global_avg_pool')\n",
    "\n",
    "        # Dense layer for classification\n",
    "        self.classifier = layers.Dense(self.num_classes, activation='softmax', name='classifier') # Use softmax for multi-class output\n",
    "\n",
    "        # It's good practice to call the parent build method\n",
    "        super().build(input_shape)\n",
    "\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # inputs should be (batch_size, 256, 256, 3)\n",
    "\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        # Apply residual blocks\n",
    "        x = self.id_block1(x)\n",
    "        x = self.id_block2(x)\n",
    "\n",
    "        # If using convolution block:\n",
    "        # x = self.conv_block1(x)\n",
    "        # x = self.id_block3(x)\n",
    "\n",
    "        # Final layers\n",
    "        x = self.global_avg_pool(x)\n",
    "        outputs = self.classifier(x)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm = Adam(learning_rate=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-7, amsgrad=False)\n",
    "\n",
    "num_epochs = 200\n",
    "\n",
    "batch = 32\n",
    "\n",
    "callbacks_list = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ELEMENT SPEC:\", train_ds.element_spec)\n",
    "for images, labels in train_ds.take(1):\n",
    "    print(\"  batch x:\", images.shape, type(images), \n",
    "          \"\\n  batch y:\", labels, labels.shape if labels is not None else None)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=20\n",
    "inputs = keras.Input((256,256,3))\n",
    "outputs = SimpleResNet(num_classes)(inputs)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SimpleResNet(num_classes)\n",
    "\n",
    "model.build((None, 256, 256, 3)) \n",
    "\n",
    "model.summary()\n",
    "\n",
    "## \"devices=None\" uses all GPUs if they're detected, or falls back to CPU if no GPUs detected\n",
    "strategy = tf.distribute.MirroredStrategy(devices=None)\n",
    "with strategy.scope():\n",
    "    model = SimpleResNet(num_classes=20)\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "start = time.time()\n",
    "history = model.fit(train_ds,\n",
    "                    epochs=num_epochs,\n",
    "                    callbacks=callbacks_list,\n",
    "                    validation_data=val_ds)\n",
    "print(f'Totally fit time: {time.time() - start:<10.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 5853248,
     "sourceId": 9595609,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
